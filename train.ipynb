{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import get_peft_model, LoraConfig\n",
    "from trl import GRPOTrainer, GRPOConfig\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "from utils import get_data,creat_index,make_conversation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d8c8547e4548f09c7dab6e1dc7929c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_set=\"scifact\"\n",
    "data_path= \"data/text_data/\"\n",
    "corpus, queries, qrels  =get_data(data_set,data_path=data_path)\n",
    "queries_ids=list(queries.keys())\n",
    "document_ids= list(corpus.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "mai 13, 2025 1:33:03 PM org.apache.lucene.store.MMapDirectory lookupProvider\n",
      "WARNING: You are running with Java 22 or later. To make full use of MMapDirectory, please update Apache Lucene.\n"
     ]
    }
   ],
   "source": [
    "index_path=\"data/index_data/\"+data_set+\"_docIndex\"\n",
    "index_path=index_path+'/doc_index'     \n",
    "creat_index(index_path,corpus)\n",
    "from pyserini.search.lucene import LuceneSearcher\n",
    "searcher = LuceneSearcher(index_path)\n",
    "searcher.set_bm25(k1=0.9, b=0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "# 2) Model\n",
    "device = torch.device(\"mps\")\n",
    "model_name = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "  model_name,torch_dtype=\"auto\",\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 36,929,536 || all params: 1,580,643,840 || trainable%: 2.3364\n"
     ]
    }
   ],
   "source": [
    "# 4) WRAP with LoRA\n",
    "peft_config = LoraConfig(\n",
    "  task_type=\"CAUSAL_LM\",\n",
    "  r=32,#size of the matrixe \n",
    "  lora_alpha=32,\n",
    "  lora_dropout=0.1,\n",
    "  target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],#where to add wieghts\n",
    "\n",
    ")\n",
    "model = get_peft_model(base_model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_func(completions, queries_id, **_):\n",
    "    # --- gather all newly-generated strings -----------------------------\n",
    "    if type(completions[0]) is list:\n",
    "        batch_queries  = [c[0]['content'] for c in completions]\n",
    "    else : batch_queries=completions\n",
    "    batch_qids     = list(queries_id)\n",
    "\n",
    "    # --- single batched call to Lucene (or Anserini) ---------------------\n",
    "    # returns {qid: [hits…]}\n",
    "    hits = searcher.batch_search(batch_queries,\n",
    "                                 batch_qids,\n",
    "                                 k=10,  # depth\n",
    "                                 threads=4)  # use 4–8; tune for your CPU / SSD\n",
    "    # --- compute metrics -------------------------------------------------\n",
    "    rewards = []\n",
    "    for qid in batch_qids:\n",
    "        scores_dict   = {d.docid: d.score for d in hits[qid]}\n",
    "        filtered      = {d: s for d, s in scores_dict.items() if d != str(qid)}\n",
    "        ndcg, *_      = EvaluateRetrieval.evaluate(qrels,\n",
    "                                                   {qid: filtered},\n",
    "                                                   [10])\n",
    "        rewards.append(ndcg['NDCG@10'])\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192b87b8df6d42ef8c601be1b182f22b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_list(\n",
    "    [{\"prompt\":value,\"queries_id\":key}  for key, value in queries.items()\n",
    "    ]\n",
    ")\n",
    "SYSTEM_PROMPT = (\n",
    "    \"A conversation between a User and an Assistant. The User provides a query to be reformulated and rich, \"\n",
    "    \"and the Assistant must rewrite the query without asking a question so that a keywords retrieval system can better find the correct document. \"\n",
    "    \"No additional text is needed — only the new, reformulated query should be returned.\\n\"\n",
    "    \"Format: USER: [ORIGINAL QUERY]  ASSISTANT: [NEW QUERY]\"\n",
    ")\n",
    "SYSTEM_PROMPT2=(\"Reformulate the query so keywords retrieval system can better find the correct document.\\n\\n\\n [ORIGINAL QUERY]: \")\n",
    "\n",
    "train_dataset = dataset.map(lambda x: make_conversation(x, SYSTEM_PROMPT2, False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'Reformulate the query so keywords retrieval system can better find the correct document.\\n\\n\\n [ORIGINAL QUERY]: 0-dimensional biomaterials show inductive properties. [NEW QUERY]:',\n",
       " 'queries_id': '1'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "# 5) GRPO TRAINER\n",
    "grpo_config = GRPOConfig(\n",
    "    output_dir=\"checkpoints/Qwen_GRPO_ex\",\n",
    "    learning_rate=1e-5,\n",
    "    remove_unused_columns=False,  # to access the solution column in accuracy_reward\n",
    "    gradient_accumulation_steps=20,\n",
    "    num_train_epochs=25,\n",
    "    #bf16=True,\n",
    "    # Parameters that control de data preprocessing\n",
    "    max_completion_length=48,  # default: 256\n",
    "    num_generations=20,  # how many querires are generated for each prompt\n",
    "    max_prompt_length=250,  # default: 512\n",
    "    # Parameters related to reporting and saving\n",
    "    report_to=[\"tensorboard\"],\n",
    "    logging_steps=20,# logging info into tensorboard on how many step\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,# save at what step\n",
    ")\n",
    "trainer = GRPOTrainer(model=model, \n",
    "                          args=grpo_config, \n",
    "                          reward_funcs=reward_func, \n",
    "                          train_dataset=train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) TRAIN\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"Ex_Great_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra to save hyber_paramters\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import json\n",
    "# Set up the logging directory\n",
    "log_dir = \"./runs/experiment-ONLY-GRPO\"\n",
    "writer = SummaryWriter(log_dir)\n",
    "for step_idx, log in enumerate(trainer.state.log_history):\n",
    "    for key, value in log.items():\n",
    "        if isinstance(value, (int, float)):  # Log scalar values only\n",
    "            writer.add_scalar(f\"metrics/{key}\", value, step_idx)\n",
    "# 1. Extract and save all config params (GRPOConfig is a subclass of dataclass)\n",
    "config_dict = grpo_config.to_dict()\n",
    "\n",
    "# Optional: save full config as JSON file\n",
    "with open(os.path.join(log_dir, \"config.json\"), \"w\") as f:\n",
    "    json.dump(config_dict, f, indent=2)\n",
    "\n",
    "# 2. Add all hyperparameters to TensorBoard\n",
    "# TensorBoard's `add_hparams()` only accepts scalar hparams, so filter them\n",
    "scalar_hparams = {\n",
    "    k: v for k, v in config_dict.items()\n",
    "    if isinstance(v, (int, float, str, bool))\n",
    "}\n",
    "\n",
    "# Get final loss (if available)\n",
    "final_loss = None\n",
    "for log in reversed(trainer.state.log_history):\n",
    "    if 'loss' in log:\n",
    "        final_loss = log['loss']\n",
    "        break\n",
    "\n",
    "writer.add_hparams(\n",
    "    scalar_hparams,\n",
    "    {'final_loss': final_loss if final_loss is not None else 0}\n",
    ")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Resources:\n",
    "https://huggingface.co/docs/trl/main/en/grpo_trainer\n",
    "https://medium.com/%40rajveer.rathod1301/fine-tuning-deepseek-7b-with-grpo-a-comprehensive-guide-1b7a89ae21b1\n",
    "https://huggingface.co/learn/cookbook/en/fine_tuning_llm_grpo_trl\n",
    "https://www.entrypointai.com/blog/lora-fine-tuning/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
